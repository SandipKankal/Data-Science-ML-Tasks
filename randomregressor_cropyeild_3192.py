# -*- coding: utf-8 -*-
"""randomregressor_cropyeild_3192.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Tanmayy123/823aa676cc033c101d6efb3d8aba2ed9/randomregressor_cropyeild_3192.ipynb
"""

# Step 1: Upload your dataset (pesticides.csv)
from google.colab import files
import pandas as pd

uploaded = files.upload()

# Step 2: Load the dataset
import io
df = pd.read_csv(io.BytesIO(uploaded['pesticides.csv']))

# Step 3: Display basic information and preview
print("Dataset Information:")
df.info()
print("\nFirst few rows of the dataset:")
print(df.head())

# Step 4: Data Cleaning
# Check for missing values
print("\nMissing values in each column:")
print(df.isnull().sum())

# Step 5: Simple Preprocessing (if needed)
# We can process 'Year', 'Area', and 'Value' for modeling, or perform one-hot encoding for categorical data.

# Example: Encoding categorical columns 'Area' and 'Item'
df_encoded = pd.get_dummies(df[['Area', 'Item']])

# Combining with the 'Year' and 'Value' columns
df_processed = pd.concat([df[['Year', 'Value']], df_encoded], axis=1)

# Step 6: Train-test split
from sklearn.model_selection import train_test_split

X = df_processed.drop('Value', axis=1)
y = df_processed['Value']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Model building (Random Forest as an example)
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 8: Model Evaluation
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5

print(f"Root Mean Squared Error: {rmse}")

# Step 9: Save the trained model (if needed)
import joblib
joblib.dump(model, 'crop_yield_model.pkl')

# Download the model
files.download('crop_yield_model.pkl')