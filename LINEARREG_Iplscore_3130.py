# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nV58IFRHCoFH1dR4QItwlXf5DfB9Xmvk
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset with error handling for malformed lines
file_path = '/content/deliveries.csv'
deliveries_df = pd.read_csv(file_path, on_bad_lines='skip')

# Handle missing dismissal_kind column
if 'dismissal_kind' in deliveries_df.columns:
    deliveries_df['dismissal_kind'].fillna(0, inplace=True)
else:
    print("Column 'dismissal_kind' not found!")
    deliveries_df['dismissal_kind'] = 0

# Data aggregation
grouped = deliveries_df.groupby(['match_id', 'inning', 'over']).agg({
    'total_runs': 'sum',
    'dismissal_kind': 'count'
}).reset_index()

# Feature engineering
grouped['cumulative_runs'] = grouped.groupby(['match_id', 'inning'])['total_runs'].cumsum()
grouped['cumulative_wickets'] = grouped.groupby(['match_id', 'inning'])['dismissal_kind'].cumsum()

# Define features and target variable
X = grouped[['over', 'cumulative_runs', 'cumulative_wickets']]
y = grouped.groupby(['match_id', 'inning'])['cumulative_runs'].transform('max')

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Linear Regression Model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)
mse_lr = mean_squared_error(y_test, y_pred_lr)

# Decision Tree Model
dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)
mse_dt = mean_squared_error(y_test, y_pred_dt)

# Random Forest Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)

# Print model performances
print(f'Linear Regression MSE: {mse_lr}')
print(f'Decision Tree MSE: {mse_dt}')
print(f'Random Forest MSE: {mse_rf}')

# Visualizations

# Boxplot of actual vs. predicted values for each model
plt.figure(figsize=(12, 6))

# Create a DataFrame for comparison
results_df = pd.DataFrame({
    'Actual': y_test,
    'Linear Regression': y_pred_lr,
    'Decision Tree': y_pred_dt,
    'Random Forest': y_pred_rf
})

# Boxplot
sns.boxplot(data=results_df)
plt.title('Boxplot of Actual vs Predicted Values')
plt.ylabel('Runs')
plt.xticks(rotation=45)
plt.show()

# Histogram of prediction errors for each model
plt.figure(figsize=(12, 6))

# Calculate errors (actual - predicted)
errors_lr = y_test - y_pred_lr
errors_dt = y_test - y_pred_dt
errors_rf = y_test - y_pred_rf

# Plot histograms for each model
plt.hist(errors_lr, bins=30, alpha=0.5, label='Linear Regression')
plt.hist(errors_dt, bins=30, alpha=0.5, label='Decision Tree')
plt.hist(errors_rf, bins=30, alpha=0.5, label='Random Forest')

plt.title('Histogram of Prediction Errors')
plt.xlabel('Error')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Scatter plots of actual vs. predicted values

plt.figure(figsize=(12, 6))

# Scatter plot for Linear Regression
plt.subplot(1, 3, 1)
plt.scatter(y_test, y_pred_lr, alpha=0.5, color='blue')
plt.title('Linear Regression: Actual vs Predicted')
plt.xlabel('Actual')
plt.ylabel('Predicted')

# Scatter plot for Decision Tree
plt.subplot(1, 3, 2)
plt.scatter(y_test, y_pred_dt, alpha=0.5, color='green')
plt.title('Decision Tree: Actual vs Predicted')
plt.xlabel('Actual')
plt.ylabel('Predicted')

# Scatter plot for Random Forest
plt.subplot(1, 3, 3)
plt.scatter(y_test, y_pred_rf, alpha=0.5, color='red')
plt.title('Random Forest: Actual vs Predicted')
plt.xlabel('Actual')
plt.ylabel('Predicted')

plt.tight_layout()
plt.show()